{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a162f72a-b331-4085-a82f-c736cb42a4dc",
   "metadata": {},
   "source": [
    "# knn-nearest-neighbor-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b370495c-a32b-4dfb-b361-1eeea810eab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in tibble(area = 12.1, perimeter = 14.2, compactness = 0.9, length = 4.9, : could not find function \"tibble\"\n",
     "output_type": "error",
     "traceback": [
      "Error in tibble(area = 12.1, perimeter = 14.2, compactness = 0.9, length = 4.9, : could not find function \"tibble\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# This is the new observation to predict\n",
    "new_seed <- tibble(area = 12.1,\n",
    "                        perimeter = 14.2,\n",
    "                        compactness = 0.9,\n",
    "                        length = 4.9,\n",
    "                        width = 2.8,\n",
    "                        asymmetry_coefficient = 3.0, \n",
    "                        groove_length = 5.1)\n",
    "\n",
    "# Read data and change the column type for our class label to \"factor\" using \"mutate\" and \"as_factor\"\n",
    "seed_data <- read_table2(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\",\n",
    "          col_names = c(\"area\",\n",
    "                        \"perimeter\",\n",
    "                        \"compactness\",\n",
    "                        \"length\",\n",
    "                        \"width\",\n",
    "                        \"asymmetry_coefficient\",\n",
    "                        \"groove_length\",\n",
    "                        \"wheat_variety\")) |>\n",
    "         mutate(wheat_variety = as_factor(wheat_variety))\n",
    "seed_data\n",
    "\n",
    "# Specifying what model we use for our analysis; we perform classification analysis with K-nearest neighbors\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "# Perform all the data processing procedures (scaling, centring...)\n",
    "seed_recipe <- recipe(wheat_variety ~ ., data = seed_data) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "# You do NOT need this step, but what this is doing is that: \n",
    "# - prep() will actually go and calculate all the steps needed to preprocess the data \n",
    "#   (i.e., actually return the newly calculated centered + scaled values)\n",
    "# - bake() will actually return a dataframe of your new data.\n",
    "seed_data_scaled <- seed_recipe |>\n",
    "    prep() |>\n",
    "    bake(seed_data)\n",
    "\n",
    "# Fit the model to the data perform prediction\n",
    "seed_fit <- workflow () |>\n",
    "    add_recipe(seed_recipe) |>\n",
    "    add_model(knn_spec) |> \n",
    "    fit(data = seed_data)\n",
    "\n",
    "# Predict the class label for the given new observation using the model you build \n",
    "seed_predict <- predict(seed_fit, new_seed)\n",
    "seed_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d167af-ad76-424d-9d78-29f6942e78de",
   "metadata": {},
   "source": [
    "# Evaluation and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238533a6-5c70-4456-aa84-25c72d8fc5d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in mutate(fruit_data, scaled_mass = scale(mass, center = TRUE), : could not find function \"mutate\"\n",
     "output_type": "error",
     "traceback": [
      "Error in mutate(fruit_data, scaled_mass = scale(mass, center = TRUE), : could not find function \"mutate\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Read the data as usual and make sure to change the class label \n",
    "# column of our interest to factor type\n",
    "\n",
    "# This is another way to scale\n",
    "fruit_data_scaled <- fruit_data |>\n",
    "    mutate(scaled_mass = scale(mass, center = TRUE),\n",
    "           scaled_width = scale(width, center = TRUE),\n",
    "           scaled_height = scale(height, center = TRUE),\n",
    "           scaled_color_score = scale(color_score, center = TRUE))\n",
    "fruit_data_scaled\n",
    "\n",
    "# Splitting the data\n",
    "fruit_split <- initial_split(fruit_data, prop = 0.75, strata = fruit_name)\n",
    "fruit_train <- training(fruit_split)\n",
    "fruit_test <- testing(fruit_split)\n",
    "\n",
    "# Exactly the same procedures EXCEPT for the data we use is \"training data.\"\n",
    "fruit_recipe\n",
    "knn_spec\n",
    "fruit_fit\n",
    "\n",
    "# Binding the columns to \"test data\"\n",
    "fruit_test_predictions <- predict(fruit_fit, fruit_test) |>\n",
    "    bind_cols(fruit_test)\n",
    "fruit_test_predictions\n",
    "\n",
    "# Metrics: to assess our classifier‚Äôs accuracy\n",
    "fruit_prediction_accuracy <- fruit_test_predictions |>\n",
    "    metrics(truth = fruit_name, estimate = .pred_class)\n",
    "fruit_prediction_accuracy\n",
    "\n",
    "# Confusion metrics: shows the table of predicted labels and correct \n",
    "# labels also to assess our classifier‚Äôs accuracy\n",
    "fruit_mat <- fruit_test_predictions |>\n",
    "    conf_mat(truth = fruit_name, estimate = .pred_class)\n",
    "fruit_mat\n",
    "\n",
    "# Cross-validation: to select which K is the most optimal for our data set for k-nn classification.\n",
    "# We split our overall training data into  ùê∂  evenly-sized chunks, \n",
    "# and then iteratively use 1 chunk as the validation set and combine \n",
    "# the remaining  ùê∂‚àí1  chunks as the training set.\n",
    "\n",
    "# To split into chunk, we use v-fold\n",
    "fruit_vfold <- vfold_cv(fruit_train, v = 5, strata = fruit_name)\n",
    "\n",
    "# Resample: for cross-validation\n",
    "fruit_resample_fit <- workflow() |>\n",
    "      add_recipe(fruit_recipe) |>\n",
    "      add_model(knn_spec) |>\n",
    "      fit_resamples(resamples = fruit_vfold)\n",
    "\n",
    "# Collect metrics: to aggregate the mean and standard error of the classifier‚Äôs \n",
    "# validation accuracy across the folds\n",
    "fruit_metrics <- collect_metrics(fruit_resample_fit)\n",
    "fruit_metrics\n",
    "\n",
    "# Tuning to fit the model for each value in a range of parameter values\n",
    "knn_tune„ÄÄ<- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"classification\")\n",
    "knn_results <- workflow() |>\n",
    "    add_recipe(fruit_recipe) |>\n",
    "    add_model(knn_tune) |>\n",
    "    tune_grid(resamples = fruit_vfold, grid = 10) |>\n",
    "    collect_metrics()\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ab52c-5353-422d-85e3-3ad5335566bf",
   "metadata": {},
   "source": [
    "# knn_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fe2d1d-34a4-455a-88b2-70f7fc8e8fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in pull(summarise(slice(arrange(mutate(data_name, diff = abs(100 - : could not find function \"pull\"\n",
     "output_type": "error",
     "traceback": [
      "Error in pull(summarise(slice(arrange(mutate(data_name, diff = abs(100 - : could not find function \"pull\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Distance between the vertical line at x (= 100) to the 4 points closest to the line\n",
    "# Take the average and show the numeric value\n",
    "answer <- data_name |> \n",
    " mutate(diff = abs(100 - x_name)) |> \n",
    " arrange(diff) |> \n",
    " slice(1:4) |>  \n",
    " summarise(predicted = mean(y_name)) |>\n",
    " pull()\n",
    "answer\n",
    "\n",
    "# All steps are similar to the classification \n",
    "credit_split <- initial_split(credit, prop = 0.6, strata = Balance)\n",
    "credit_training <- training(credit_split)\n",
    "credit_testing <- testing(credit_split)\n",
    "\n",
    "# **** NOT the same ****\n",
    "credit_knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"regression\")\n",
    "\n",
    "credit_knn_recipe <- recipe(Balance ~., data = credit_training) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors())\n",
    "\n",
    "credit_vfold <- vfold_cv(credit_training, v = 5, strata = Balance)\n",
    "\n",
    "# **** NOT the same ****\n",
    "credit_knn_workflow <- workflow() |>\n",
    "    add_recipe(credit_knn_recipe) |>\n",
    "    add_model(credit_knn_spec)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(1,20))\n",
    "\n",
    "credit_knn_results <- credit_knn_workflow |>\n",
    "    tune_grid(resamples = credit_vfold, grid = gridvals) |>\n",
    "    collect_metrics() \n",
    "\n",
    "# **** select the value of k resulting in best RMSE ****\n",
    "kmin <- credit_knn_results |>\n",
    "   filter(.metric == \"rmse\") |>\n",
    "   arrange(mean) |> \n",
    "   slice(1) |>\n",
    "   pull(neighbors)\n",
    "\n",
    "# **** retrain the model using that final k, predict on held-out data ****\n",
    "credit_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = kmin) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"regression\")\n",
    "\n",
    "credit_fit <- workflow() |>\n",
    "  add_recipe(credit_knn_recipe) |>\n",
    "  add_model(credit_spec) |>\n",
    "  fit(data = credit_training)\n",
    "\n",
    "knn_rmspe <- credit_fit |>\n",
    "  predict(credit_testing) |>\n",
    "  bind_cols(credit_testing) |>\n",
    "  metrics(truth = Balance, estimate = .pred)|>\n",
    "  filter(.metric == 'rmse') |>\n",
    "  pull(.estimate) \n",
    "\n",
    "# **** knn-regression plot ****\n",
    "marathon_preds <- marathon_best_fit |>\n",
    "                predict(marathon_training) |>\n",
    "                bind_cols(marathon_training)\n",
    "\n",
    "marathon_plot <- ggplot(marathon_preds, aes(x = max, y = time_hrs)) +\n",
    "            geom_point(alpha = 0.4) +\n",
    "            xlab(\"Maximum Distance Ran per \\n Week During Training (mi)\") +\n",
    "            ylab(\"Race Time (hours)\") + \n",
    "            geom_line(data = marathon_preds, aes(x = max, y = .pred), color = \"blue\") +\n",
    "            ggtitle(paste0(\"K = \", k_min)) +\n",
    "            theme(text = element_text(size = 20))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c28916c-339f-48df-8435-18d1100a6abe",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96104107-b08b-4645-b8cc-96bc98894d40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read_csv(\"data/marathon.csv\"): could not find function \"read_csv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_csv(\"data/marathon.csv\"): could not find function \"read_csv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "marathon <- read_csv('data/marathon.csv')\n",
    "\n",
    "# split data\n",
    "marathon_split <- initial_split(marathon, prop = 0.75, strata = time_hrs)\n",
    "marathon_training <- training(marathon_split)\n",
    "marathon_testing <- testing(marathon_split)\n",
    "\n",
    "# specify the model\n",
    "lm_spec <- linear_reg() |>\n",
    "            set_engine(\"lm\") |>\n",
    "            set_mode(\"regression\")\n",
    "\n",
    "# recipe and fit\n",
    "lm_recipe <- recipe(time_hrs ~ max, data = marathon_training)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "            add_recipe(lm_recipe) |>\n",
    "            add_model(lm_spec) |>\n",
    "            fit(data = marathon_training)\n",
    "\n",
    "# predictions for RMSE\n",
    "# ***********************************************\n",
    "\n",
    "lm_test_results_rmse <- lm_fit |>\n",
    "                    predict(marathon_training) |>\n",
    "                    bind_cols(marathon_training) |>\n",
    "                    metrics(truth = time_hrs, estimate = .pred)                 \n",
    "\n",
    "# extracting the RMSPE (*** BECAUSE WE ARE USING TESTING DATA ***)\n",
    "lm_rmse <- lm_test_results_rmse |>\n",
    "                filter(.metric == 'rmse') |>\n",
    "                select(.estimate) |>\n",
    "                pull()\n",
    "\n",
    "# predictions for RMSPE\n",
    "# ***********************************************\n",
    "\n",
    "lm_test_results_rmspe <- lm_fit |>\n",
    "                    predict(marathon_testing) |>\n",
    "                    bind_cols(marathon_testing) |>\n",
    "                    metrics(truth = time_hrs, estimate = .pred)                 \n",
    "\n",
    "# extracting the RMSPE (*** BECAUSE WE ARE USING TESTING DATA ***)\n",
    "lm_rmspe <- lm_test_results_rmspe |>\n",
    "                filter(.metric == 'rmse') |>\n",
    "                select(.estimate) |>\n",
    "                pull()\n",
    "\n",
    "# ***********************************************\n",
    "\n",
    "# **** Simple Linear Regression Plot ***\n",
    "lm_predictions <- ggplot(marathon_training, aes(x=max, y=time_hrs)) +\n",
    "    geom_point(alpha = 0.4) +\n",
    "    xlab(\"Max)\") +\n",
    "    ylab(\"Time in Hours\") +\n",
    "    geom_smooth(method = \"lm\", se = FALSE) + \n",
    "    theme(text = element_text(size = 12))\n",
    "lm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eccb2c-33b9-4605-9e21-28b8f1c6c705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
